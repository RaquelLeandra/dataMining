{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques for Unbalanced datasets\n",
    "(by Mario Martin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of examples of the smaller class (class 1): 10.00%\n",
      "train:  10.0 \n",
      "test:  10.0\n"
     ]
    }
   ],
   "source": [
    "#Let's generate an unbalanced dataset:\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "n_samples_1 = 100000\n",
    "n_samples_2 = 8000\n",
    "X = np.r_[1.5 * rng.randn(n_samples_1, 2),\n",
    "          0.5 * rng.randn(n_samples_2, 2) + [2, 2]]\n",
    "y = np.array([0] * (n_samples_1) + [1] * (n_samples_2))\n",
    "\n",
    "X, y = datasets.make_classification(n_classes=2, class_sep=0.1, weights=[0.9, 0.1],\n",
    "                           n_informative=3, n_redundant=0, flip_y=0,\n",
    "                           n_features=5, n_clusters_per_class=2,\n",
    "                           n_samples=5000, random_state=10)\n",
    "\n",
    "\n",
    "# Let's separate data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.5,stratify=y)\n",
    "\n",
    "# Proportion of examples in the smaller class (class 1) is the following\n",
    "\n",
    "print(\"Percentage of examples of the smaller class (class 1): {0:.2f}%\".format(100*np.sum(y==1)/(np.sum(y==0)+np.sum(y==1))))\n",
    "\n",
    "print('train: ',100*np.sum(y_train==1)/(np.sum(y_train==0)+np.sum(y_train==1)), '\\ntest: ',100*np.sum(y_test==1)/(np.sum(y_test==0)+np.sum(y_train==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 9, 'weights': 'distance'} \n",
      "Accuracy on 10-fold cross-validation= 0.9168\n",
      "Accuracy on test set: 0.8988\n"
     ]
    }
   ],
   "source": [
    "# Let's optimize k-nn for this dataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb          # Per fer servir el knn\n",
    "\n",
    "# Maximizing Accuracy\n",
    "params = {'n_neighbors':list(range(1,30,2)), 'weights':('uniform','distance')}\n",
    "knc = nb.KNeighborsClassifier()\n",
    "clf = GridSearchCV(knc, param_grid=params,cv=10,n_jobs=-1)  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best Params=\",clf.best_params_, \"\\nAccuracy on 10-fold cross-validation=\", clf.best_score_)\n",
    "parval=clf.best_params_\n",
    "knc = nb.KNeighborsClassifier(n_neighbors=parval['n_neighbors'],weights=parval['weights'])\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy on test set:\",accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good accuracy, but in these cases we have to observe the confusion matrix and focus not on accuracy but on recall and precision measures of the smaller class (or the f-measure that is the geometrical combination of both).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on test set:\n",
      " [[2220   10]\n",
      " [ 243   27]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95      2230\n",
      "          1       0.73      0.10      0.18       270\n",
      "\n",
      "avg / total       0.88      0.90      0.86      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion matrix on test set:\\n\",confusion_matrix(y_test, pred))\n",
    "print(\"\\n \",classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. f1-score of 0.18 is very low. Notice that recall for class 1 is only 0.1 (in second row of confussion matrix, we can see that we only catch 27 of 243+27 cases, that is, 0.1 of recall)... Too bad.\n",
    "\n",
    "This effect is expected In higly unbalanced datasets. In order to improve these values, there are several techniques that can be applied.\n",
    "\n",
    "\n",
    "## 1- Changing performance function\n",
    "\n",
    "When optimizing parameters, try to focus on the optimization these measures (f-score, recall or precision) instead of optimizing accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params= {'n_neighbors': 1, 'weights': 'uniform'} \n",
      "F-score on 10-fold crossvalidation= 0.375360380407\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[2098  132]\n",
      " [ 176   94]]\n",
      "\n",
      "Accuracy on test set: 0.8768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93      2230\n",
      "          1       0.42      0.35      0.38       270\n",
      "\n",
      "avg / total       0.87      0.88      0.87      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's optimize f1_score by creationg an scoring function \"f_scorer\"\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "# Maximizing f1_score for class 1\n",
    "f_scorer = make_scorer(f1_score,pos_label=1)\n",
    "\n",
    "params = {'n_neighbors':list(range(1,30,2)), 'weights':('uniform','distance')}\n",
    "knc = nb.KNeighborsClassifier()\n",
    "clf = GridSearchCV(knc, param_grid=params,cv=10,n_jobs=-1,scoring=f_scorer)  # If cv is integer, by default is Stratifyed \n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best Params=\",clf.best_params_, \"\\nF-score on 10-fold crossvalidation=\", clf.best_score_)\n",
    "parval=clf.best_params_\n",
    "knc = nb.KNeighborsClassifier(n_neighbors=parval['n_neighbors'],weights=parval['weights'])\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"\\nConfusion matrix on test set:\\n\",confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set:\",accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have f1-score for class 1 of 0.38 instead of 0.18. Nice improvement.\n",
    "\n",
    "This method can be applied when we have parameters to adjust... but no in Naive Bayes, for instance, because it has no parameters to adjust. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Finding good threshold function (recomended approach)\n",
    "\n",
    "When running a classifier, instead of returning hard decisions about belonging to a class or the other, return the probability of belonging to the minority class. Probabilities can be estimated for most algorithms implemented in sklearn. Once we have the probabilities we will adjust the threshold on these probabilities to decide where belongs each element. The threshold will be set so it maximizes the f-measure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95      2230\n",
      "          1       0.85      0.12      0.21       270\n",
      "\n",
      "avg / total       0.90      0.90      0.87      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try Naive Bayes on hard decisions\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an f1-score of only 0.21. Let's try to impove it by selecting a good threshold for probability values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inanna\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected threshold in 10-fold cross validation: 0.209974976216\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      2230\n",
      "          1       0.55      0.50      0.53       270\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def filterp(th,ProbClass1):\n",
    "    \"\"\" Given a treshold \"th\" and a set of probabilies of belonging to class 1 \"ProbClass1\", return predictions \"\"\" \n",
    "    y=np.zeros(ProbClass1.shape[0])\n",
    "    for i,v in enumerate(ProbClass1):\n",
    "        if ProbClass1[i]>th:\n",
    "            y[i]=1\n",
    "    return y  \n",
    "\n",
    "clf = GaussianNB()\n",
    "lth=[]\n",
    "\n",
    "# We do a 10 fold crossvalidation with 10 iterations\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train2, X_test2 = X[train_index], X[test_index]\n",
    "    y_train2, y_test2 = y[train_index], y[test_index]\n",
    "\n",
    "    # Train with the training data of the iteration \n",
    "    clf.fit(X_train2, y_train2)\n",
    "    # Obtaining probablity predictions for test data of the iterarion\n",
    "    probs = clf.predict_proba(X_test2)\n",
    "    # Collect probabilities of belonging to class 1\n",
    "    ProbClass1 = probs[:,1]\n",
    "    # Sort probabilities and generate pairs (threshold, f1-for-that-threshold) \n",
    "    res = np.array([[th,f1_score(y_test2,filterp(th,ProbClass1),pos_label=1)] for th in np.sort(ProbClass1)])\n",
    "\n",
    "    # Uncomment the following lines if you want to plot at each iteration how f1-score evolves increasing the threshold \n",
    "    #plt.plot(res[:,0],res[:,1])\n",
    "    #plt.show()\n",
    "\n",
    "    # Find the threshold that has maximum value of f1-score\n",
    "    maxF = np.max(res[:,1])\n",
    "    optimal_th = res[res[:,1]==maxF,0]\n",
    "    \n",
    "    # Store the optimal threshold found for the current iteration\n",
    "    lth.append(optimal_th)\n",
    "\n",
    "# Compute the average threshold for all 10 iterations    \n",
    "thdef = np.mean(lth)\n",
    "print(\"Selected threshold in 10-fold cross validation:\", thdef)\n",
    "print()\n",
    "\n",
    "# Train a classifier with the whole training data \n",
    "clf.fit(X_train, y_train)\n",
    "# Obtain probabilities for data on test set\n",
    "probs = clf.predict_proba(X_test)\n",
    "# Generate predictions using probabilities and threshold found on 10 folds cross-validation\n",
    "pred = filterp(thdef,probs[:,1])\n",
    "# Print results with this prediction vector\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Ignore warnings explaining that in some iterations f1 score is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increased from an f1 of Naive Bayes of 0.21 to 0.53 by adjusting the probability threshold.\n",
    "\n",
    "The same trick can be done for any algorithm implemented in python that has method \"predict_proba\" implemented. It also can be used when the fuction you want to optimize is not f-score of one class but any other you want. the only thing you have to do is change the calls to f1_score by your function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Sampling approach:\n",
    "\n",
    "a) Oversampling of the minority class, \n",
    "\n",
    "b) undersampling of the majority class and,\n",
    "\n",
    "c) artificial generation of examples for the minoiry class\n",
    "\n",
    "To do that, you have to previously keep a test set with the original proportion of data to obtain the performance measure (because them have to be computed on a dataset with the true distribution of examples on each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The asiest way to deal with unbalanced datasets with sampling procedures is to use the imblearn package in python\n",
    "#   http://contrib.scikit-learn.org/imbalanced-learn/stable/index.html\n",
    "# Instalation mcan be done with pip or conda (if you use conda, this is recomended). Instalation is done with one\n",
    "# of the following commands:\n",
    "#    conda install -c glemaitre imbalanced-learn\n",
    "#    pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Results for Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95      2230\n",
      "          1       0.85      0.12      0.21       270\n",
      "\n",
      "avg / total       0.90      0.90      0.87      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[2224    6]\n",
      " [ 237   33]]\n",
      "\n",
      "** Results OVERSAMPLING randomly\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.71      0.82      2230\n",
      "          1       0.27      0.89      0.41       270\n",
      "\n",
      "avg / total       0.90      0.73      0.78      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[1585  645]\n",
      " [  31  239]]\n"
     ]
    }
   ],
   "source": [
    "# Solution doing oversampling of the smaller class\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn import pipeline as pl\n",
    "\n",
    "RANDOM_STATE=42\n",
    "\n",
    "pipeline = pl.make_pipeline(GaussianNB())\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(\"\\n** Results for Naive Bayes\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n",
    "\n",
    "pipeline = pl.make_pipeline(RandomOverSampler(random_state=RANDOM_STATE), GaussianNB())\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(\"\\n** Results OVERSAMPLING randomly\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Results for UNDERSAMPLING with method Random\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.71      0.83      2230\n",
      "          1       0.27      0.89      0.42       270\n",
      "\n",
      "avg / total       0.91      0.73      0.78      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[1592  638]\n",
      " [  30  240]]\n",
      "\n",
      "** Results for UNDERSAMPLING with method Instance Hardness threshold\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      2230\n",
      "          1       0.79      0.22      0.35       270\n",
      "\n",
      "avg / total       0.90      0.91      0.89      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[2214   16]\n",
      " [ 210   60]]\n",
      "\n",
      "** Results for UNDERSAMPLING with method Condensed Nearest Neighbour\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95      2230\n",
      "          1       0.66      0.40      0.49       270\n",
      "\n",
      "avg / total       0.90      0.91      0.90      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[2174   56]\n",
      " [ 163  107]]\n"
     ]
    }
   ],
   "source": [
    "# Solution doing undersampling of the larger class. There are several method implemented. \n",
    "# I recommend any of the following ones:\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler,CondensedNearestNeighbour,InstanceHardnessThreshold\n",
    "\n",
    "pipeline = pl.make_pipeline(RandomUnderSampler(random_state=RANDOM_STATE), GaussianNB())\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(\"\\n** Results for UNDERSAMPLING with method Random\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n",
    "\n",
    "pipeline = pl.make_pipeline(InstanceHardnessThreshold(random_state=RANDOM_STATE), GaussianNB())\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(\"\\n** Results for UNDERSAMPLING with method Instance Hardness threshold\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n",
    "    \n",
    "pipeline = pl.make_pipeline(CondensedNearestNeighbour(random_state=RANDOM_STATE), GaussianNB())\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(\"\\n** Results for UNDERSAMPLING with method Condensed Nearest Neighbour\")\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.73      0.83      2230\n",
      "          1       0.27      0.83      0.41       270\n",
      "\n",
      "avg / total       0.90      0.74      0.79      2500\n",
      "\n",
      "\n",
      " Confusion matrix on test set:\n",
      " [[1630  600]\n",
      " [  46  224]]\n"
     ]
    }
   ],
   "source": [
    "# Solution creating artificial examples of the smaller class\n",
    "from imblearn import over_sampling as os\n",
    "\n",
    "pipeline = pl.make_pipeline(os.SMOTE(random_state=RANDOM_STATE), GaussianNB())\n",
    "\n",
    "# Train the classifier with balancing\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_bal))\n",
    "print(\"\\n Confusion matrix on test set:\\n\",confusion_matrix(y_test, y_pred_bal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final notes\n",
    "There are some algorithm, for instance SVM, where you can introduce the weigth of each class in the calssification class. See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Cs [  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
      "   1.00000000e+02]\n",
      "Best C = 100.0\n",
      "\n",
      "** Results for Plain SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95      2230\n",
      "          1       0.72      0.30      0.42       270\n",
      "\n",
      "avg / total       0.90      0.91      0.89      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[2198   32]\n",
      " [ 189   81]]\n",
      "Best C = 100.0\n",
      "\n",
      "** Results for Plain SVM with ratio for class 1 set to 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.83      0.89      2230\n",
      "          1       0.34      0.73      0.46       270\n",
      "\n",
      "avg / total       0.89      0.82      0.84      2500\n",
      "\n",
      "Confusion matrix on test set:\n",
      " [[1844  386]\n",
      " [  74  196]]\n"
     ]
    }
   ],
   "source": [
    "# Especial case for SVM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "Cs = np.logspace(-2, 2, num=5, base=10.0)\n",
    "print(\"Tested Cs\", Cs)\n",
    "param_grid = {'C': Cs}\n",
    "\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "parval=grid_search.best_params_\n",
    "print(\"Best C =\", parval['C'])\n",
    "clf = svm.SVC(kernel='rbf',C=parval['C'])\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"\\n** Results for Plain SVM\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, pred))\n",
    " \n",
    "\n",
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf', class_weight={1: 10}), param_grid, cv=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "parval=grid_search.best_params_\n",
    "print(\"Best C =\", parval['C'])\n",
    "clf = svm.SVC(kernel='rbf',C=parval['C'], class_weight={1: 10})\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"\\n** Results for Plain SVM with ratio for class 1 set to 10\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"Confusion matrix on test set:\\n\",confusion_matrix(y_test, pred))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results with SVM are not very good because we haven't adjusted the gamma parameter, only C parameter is adjusted....  but the idea is there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
